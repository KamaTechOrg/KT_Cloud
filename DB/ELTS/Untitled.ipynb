{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ca7558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_updated: 2024-09-14 21:29:40\n",
      "Filtered Customers:\n",
      "Empty DataFrame\n",
      "Columns: [CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId, UpdatedAt]\n",
      "Index: []\n",
      "Filtered Invoices:\n",
      "     InvoiceId  CustomerId       InvoiceDate  \\\n",
      "225        226          40  21/09/2023 00:00   \n",
      "226        227          44  22/09/2023 00:00   \n",
      "227        228          50  25/09/2023 00:00   \n",
      "256        257          34  01/02/2024 00:00   \n",
      "257        258          48  09/02/2024 00:00   \n",
      "258        259          49  22/02/2024 00:00   \n",
      "285        286          23  12/06/2024 00:00   \n",
      "286        287          24  25/06/2024 00:00   \n",
      "287        288          26  25/06/2024 00:00   \n",
      "316        317           3  28/10/2024 00:00   \n",
      "317        318           7  29/10/2024 00:00   \n",
      "318        319          13  01/11/2024 00:00   \n",
      "346        347          47  05/03/2025 00:00   \n",
      "347        348          56  10/03/2025 00:00   \n",
      "348        349          11  18/03/2025 00:00   \n",
      "377        378          46  02/08/2025 00:00   \n",
      "378        379          48  02/08/2025 00:00   \n",
      "379        380          50  03/08/2025 00:00   \n",
      "407        408          25  05/12/2025 00:00   \n",
      "408        409          29  06/12/2025 00:00   \n",
      "409        410          35  09/12/2025 00:00   \n",
      "\n",
      "                               BillingAddress   BillingCity BillingState  \\\n",
      "225                            8, Rue Hanovre         Paris          NaN   \n",
      "226                           Porthaninkatu 9      Helsinki          NaN   \n",
      "227                        C/ San Bernardo 85        Madrid          NaN   \n",
      "256                        Rua da Assunção 53        Lisbon          NaN   \n",
      "257                     Lijnbaansgracht 120bg     Amsterdam           VV   \n",
      "258                              Ordynacka 10        Warsaw          NaN   \n",
      "285                           69 Salem Street        Boston           MA   \n",
      "286                     162 E Superior Street       Chicago           IL   \n",
      "287                       2211 W Berry Street    Fort Worth           TX   \n",
      "316                         1498 rue Bélanger      Montréal           QC   \n",
      "317      Rotenturmstraße 4, 1010 Innere Stadt        Vienne          NaN   \n",
      "318                              Qe 7 Bloco G      Brasília           DF   \n",
      "346                    Via Degli Scipioni, 43          Rome           RM   \n",
      "347                        307 Macacha Güemes  Buenos Aires          NaN   \n",
      "348                        Av. Paulista, 2022     São Paulo           SP   \n",
      "377                          3 Chatham Street        Dublin       Dublin   \n",
      "378                     Lijnbaansgracht 120bg     Amsterdam           VV   \n",
      "379                        C/ San Bernardo 85        Madrid          NaN   \n",
      "407                     319 N. Frances Street       Madison           WI   \n",
      "408                    796 Dundas Street West       Toronto           ON   \n",
      "409  Rua dos Campeões Europeus de Viena, 4350         Porto          NaN   \n",
      "\n",
      "    BillingCountry BillingPostalCode  Total  UpdatedAt  \n",
      "225         France             75002   3.96 2024-10-01  \n",
      "226        Finland               530   5.94 2024-11-01  \n",
      "227          Spain             28015   8.91 2024-12-01  \n",
      "256       Portugal               NaN  13.86 2024-10-02  \n",
      "257    Netherlands              1016   0.99 2024-11-02  \n",
      "258         Poland            00-358   1.98 2024-12-02  \n",
      "285            USA              2113   0.99 2024-10-03  \n",
      "286            USA             60611   1.98 2024-11-03  \n",
      "287            USA             76110   1.98 2024-12-03  \n",
      "316         Canada           H2G 1A7   3.96 2024-10-04  \n",
      "317        Austria              1010   5.94 2024-11-04  \n",
      "318         Brazil         71020-677   8.91 2024-12-04  \n",
      "346          Italy               192   8.91 2024-10-05  \n",
      "347      Argentina              1106  13.86 2024-11-05  \n",
      "348         Brazil         01310-200   0.99 2024-12-05  \n",
      "377        Ireland               NaN   1.98 2024-10-06  \n",
      "378    Netherlands              1016   1.98 2024-11-06  \n",
      "379          Spain             28015   3.96 2024-12-06  \n",
      "407            USA             53703   3.96 2024-10-07  \n",
      "408         Canada           M6J 1V1   5.94 2024-11-07  \n",
      "409       Portugal               NaN   8.91 2024-12-07  \n",
      "Filtered Invoice Lines:\n",
      "      InvoiceLineId  InvoiceId  TrackId  UnitPrice  Quantity  UpdatedAt\n",
      "225             226         41     1390       0.99         1 2024-10-01\n",
      "226             227         42     1391       0.99         1 2024-11-01\n",
      "227             228         42     1392       0.99         1 2024-12-01\n",
      "256             257         47     1554       0.99         1 2024-10-02\n",
      "257             258         47     1563       0.99         1 2024-11-02\n",
      "...             ...        ...      ...        ...       ...        ...\n",
      "2231           2232        411     3100       0.99         1 2029-08-07\n",
      "2232           2233        411     3109       0.99         1 2029-09-07\n",
      "2233           2234        411     3118       0.99         1 2029-10-07\n",
      "2234           2235        411     3127       0.99         1 2029-11-07\n",
      "2235           2236        411     3136       0.99         1 2029-12-07\n",
      "\n",
      "[696 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def incremental_load():\n",
    "    conn = sqlite3.connect('../../../Customers_ELT.db')\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        # EXTRACT (Loading CSVs from S3 or local storage)\n",
    "        customers = pd.read_csv(\"../../../Customer.csv\")\n",
    "        invoices = pd.read_csv(\"../../../Invoice.csv\")\n",
    "        invoice_lines = pd.read_csv(\"../../../InvoiceLine.csv\")\n",
    "\n",
    "        # Check if the 'customer_loyalty' table exists\n",
    "        cursor.execute(\"\"\"\n",
    "             SELECT name FROM sqlite_master WHERE type='table' AND name='customer_loyalty_and_invoice_size_ELT';\n",
    "         \"\"\")\n",
    "        table_exists = cursor.fetchone()\n",
    "\n",
    "        # If the table exists, get the latest processed updated_at from the customer_loyalty table\n",
    "        if table_exists:\n",
    "            latest_updated_at_query = \"SELECT MAX(updated_at) FROM customer_loyalty_and_invoice_size_ELT\"\n",
    "            cursor.execute(latest_updated_at_query)\n",
    "            last_updated  = cursor.fetchone()[0]\n",
    "\n",
    "        if not table_exists or last_updated  is None:\n",
    "            last_updated  = '1900-01-01 00:00:00'  # Default to a very old timestamp\n",
    "#         print(last_updated)\n",
    "#         last_updated = pd.to_datetime(last_updated)\n",
    "#         print(last_updated)\n",
    "#         # Filter rows that have been created or updated after the last load\n",
    "#         customers_filtered = customers[pd.to_datetime(customers['UpdatedAt']) > last_updated]\n",
    "#         invoices_filtered = invoices[pd.to_datetime(invoices['UpdatedAt']) > last_updated]\n",
    "#         invoice_lines_filtered = invoice_lines[pd.to_datetime(invoice_lines['UpdatedAt']) > last_updated]\n",
    "#         print(customers_filtered,invoices_filtered, invoice_lines_filtered)\n",
    "#         # Load filtered data into temporary tables\n",
    "\n",
    "        last_updated = pd.to_datetime(last_updated)\n",
    "        print(f\"last_updated: {last_updated}\")\n",
    "\n",
    "        # Convert 'UpdatedAt' to datetime format, assuming format is MM/DD/YYYY\n",
    "        customers['UpdatedAt'] = pd.to_datetime(customers['UpdatedAt'], format='%m/%d/%Y', errors='coerce')\n",
    "        invoices['UpdatedAt'] = pd.to_datetime(invoices['UpdatedAt'], format='%m/%d/%Y', errors='coerce')\n",
    "        invoice_lines['UpdatedAt'] = pd.to_datetime(invoice_lines['UpdatedAt'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "        # Print first few rows to check the dates\n",
    "#         print(customers['UpdatedAt'].head())\n",
    "#         print(invoices['UpdatedAt'].head())\n",
    "#         print(invoice_lines['UpdatedAt'].head())\n",
    "\n",
    "        # Filter rows that have been created or updated after the last load\n",
    "        customers_filtered = customers[customers['UpdatedAt'] > last_updated]\n",
    "        invoices_filtered = invoices[invoices['UpdatedAt'] > last_updated]\n",
    "        invoice_lines_filtered = invoice_lines[invoice_lines['UpdatedAt'] > last_updated]\n",
    "\n",
    "        # Print filtered data to verify\n",
    "        print(\"Filtered Customers:\")\n",
    "        print(customers_filtered)\n",
    "        print(\"Filtered Invoices:\")\n",
    "        print(invoices_filtered)\n",
    "        print(\"Filtered Invoice Lines:\")\n",
    "        print(invoice_lines_filtered)\n",
    "        \n",
    "        \n",
    "        customers_filtered.to_sql('Customers_temp', conn, if_exists='replace', index=False)\n",
    "        invoices_filtered.to_sql('Invoices_temp', conn, if_exists='replace', index=False)\n",
    "        invoice_lines_filtered.to_sql('Invoices_Line_temp', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # Save historical data for customers to be updated (loyalty_score, avg_invoice_size, created_at)\n",
    "        conn.execute(\"\"\"DROP TABLE IF EXISTS customers_old_data_temp\"\"\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE customers_old_data_temp AS\n",
    "            SELECT CustomerId, loyalty_score, avg_invoice_size, created_at\n",
    "            FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Remove the existing rows from the target table for customers being updated\n",
    "        conn.execute(\"\"\"\n",
    "            DELETE FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # TRANSFORM (Perform transformations and combine with old data)\n",
    "        transform_query = \"\"\"\n",
    "            INSERT INTO customer_loyalty_and_invoice_size_ELT \n",
    "            (CustomerId, FirstName, LastName, loyalty_score, avg_invoice_size, created_at, updated_at, updated_by)\n",
    "            SELECT \n",
    "                C.CustomerId,\n",
    "                C.FirstName,\n",
    "                C.LastName,\n",
    "                COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId) AS loyalty_score,  -- Combine old and new loyalty score\n",
    "                (\n",
    "                    (COALESCE(O.loyalty_score, 0) * COALESCE(O.avg_invoice_size, 0)) + SUM(IL.total_spend)\n",
    "                ) / NULLIF(COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId), 0) AS avg_invoice_size,  -- Combine old and new avg invoice size\n",
    "                COALESCE(O.created_at, CURRENT_TIMESTAMP) AS created_at,  -- Retain old created_at or set to current\n",
    "                CURRENT_TIMESTAMP AS updated_at,\n",
    "                'process:SL' AS updated_by\n",
    "            FROM \n",
    "                Customers_temp C\n",
    "            LEFT JOIN Invoices_temp I ON C.CustomerId = I.CustomerId\n",
    "            LEFT JOIN (\n",
    "                SELECT InvoiceId, SUM(UnitPrice * Quantity) AS total_spend\n",
    "                FROM Invoices_Line_temp\n",
    "                GROUP BY InvoiceId\n",
    "            ) IL ON I.InvoiceId = IL.InvoiceId\n",
    "            LEFT JOIN customers_old_data_temp O ON C.CustomerId = O.CustomerId\n",
    "            GROUP BY \n",
    "                C.CustomerId, C.FirstName, C.LastName;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the transformation query\n",
    "        conn.execute(transform_query)\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        # Clean up temporary tables\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Customers_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_Line_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS customers_old_data_temp\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Close the SQLite connection\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "incremental_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d8a84e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Luís', 'Gonçalves', 10, 5.660000000000001, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(2, 'Leonie', 'Köhler', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(3, 'François', 'Tremblay', 7, 5.659999999999999, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(4, 'Bjørn', 'Hansen', 7, 5.659999999999999, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(5, 'František', 'Wichterlová', 7, 5.802857142857143, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(6, 'Helena', 'Holý', 7, 7.088571428571427, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(7, 'Astrid', 'Gruber', 7, 6.088571428571428, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(8, 'Daan', 'Peeters', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(9, 'Kara', 'Nielsen', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(10, 'Eduardo', 'Martins', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(11, 'Alexandre', 'Rocha', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(12, 'Roberto', 'Almeida', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(13, 'Fernanda', 'Ramos', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(14, 'Mark', 'Philips', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(15, 'Jennifer', 'Peterson', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(16, 'Frank', 'Harris', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(17, 'Jack', 'Smith', 7, 5.660000000000001, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(18, 'Michelle', 'Brooks', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(19, 'Tim', 'Goyer', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(20, 'Dan', 'Miller', 7, 5.659999999999999, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(21, 'Kathy', 'Chase', 7, 5.374285714285714, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(22, 'Heather', 'Leacock', 7, 5.660000000000001, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(23, 'John', 'Gordon', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(24, 'Frank', 'Ralston', 7, 6.231428571428571, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(25, 'Victor', 'Stevens', 7, 6.088571428571428, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(26, 'Richard', 'Cunningham', 7, 6.802857142857142, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(27, 'Patrick', 'Gray', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(28, 'Julia', 'Barnett', 7, 6.231428571428572, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(29, 'Robert', 'Brown', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(30, 'Edward', 'Francis', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(31, 'Martha', 'Silk', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(32, 'Aaron', 'Mitchell', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(33, 'Ellie', 'Sullivan', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(34, 'João', 'Fernandes', 7, 5.660000000000001, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(35, 'Madalena', 'Sampaio', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(36, 'Hannah', 'Schneider', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(37, 'Fynn', 'Zimmermann', 7, 6.231428571428571, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(38, 'Niklas', 'Schröder', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(39, 'Camille', 'Bernard', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(40, 'Dominique', 'Lefebvre', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(41, 'Marc', 'Dubois', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(42, 'Wyatt', 'Girard', 7, 5.659999999999999, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(43, 'Isabelle', 'Mercier', 7, 5.802857142857143, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(44, 'Terhi', 'Hämäläinen', 7, 5.945714285714287, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(45, 'Ladislav', 'Kovács', 7, 6.517142857142857, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(46, 'Hugh', \"O'Reilly\", 7, 6.517142857142856, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(47, 'Lucas', 'Mancini', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(48, 'Johannes', 'Van der Berg', 7, 5.8028571428571425, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(49, 'Stanisław', 'Wójcik', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(50, 'Enrique', 'Muñoz', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(51, 'Joakim', 'Johansson', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(52, 'Emma', 'Jones', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(53, 'Phil', 'Hughes', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(54, 'Steve', 'Murray', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(55, 'Mark', 'Taylor', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(56, 'Diego', 'Gutiérrez', 7, 5.3742857142857146, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(57, 'Luis', 'Rojas', 7, 6.659999999999999, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(58, 'Manoj', 'Pareek', 7, 5.517142857142858, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n",
      "(59, 'Puja', 'Srivastava', 6, 6.1066666666666665, '2024-09-14 22:16:05', '2024-09-14 22:16:05', 'process:SL')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('../../../Customers_ELT.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query to check if a row with the given CustomerId exists\n",
    "check_query = \"SELECT * FROM customer_loyalty_and_invoice_size_ELT\"\n",
    "\n",
    "# Execute the query with the specific CustomerId\n",
    "cursor.execute(check_query)\n",
    "\n",
    "# Fetch all rows from the result set\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Print each row\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f541dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sqlite3  # Assuming you're using sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def load():\n",
    "\n",
    "    conn = sqlite3.connect('../../../Customers_ELT.db')\n",
    "\n",
    "    try:\n",
    "        # EXTRACT (Loading CSVs from S3 or local storage)\n",
    "        # -----------------------------------------------\n",
    "        customers = pd.read_csv(\"../../../Customer.csv\")\n",
    "        invoices = pd.read_csv(\"../../../Invoice.csv\")\n",
    "        invoice_lines = pd.read_csv(\"../../../InvoiceLine.csv\")\n",
    "\n",
    "\n",
    "        # LOAD (Save the raw data into SQLite without transformation)\n",
    "        # -----------------------------------------------------------------------\n",
    "        # Load raw data into SQLite\n",
    "        customers.to_sql('Customers', conn, if_exists='replace', index=False)\n",
    "        invoices.to_sql('Invoices', conn, if_exists='replace', index=False)\n",
    "        invoice_lines.to_sql('Invoices_Line', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # TRANSFORM (Perform transformations with SQL queries using KT_DB functions)\n",
    "        # -------------------------------------------------------------------------\n",
    "        drop_query=\"\"\"DROP TABLE IF EXISTS customer_loyalty_and_invoice_size_ELT\"\"\"\n",
    "        conn.execute(drop_query)\n",
    "        conn.commit()\n",
    "\n",
    "        transform_query = \"\"\"\n",
    "            CREATE TABLE customer_loyalty_and_invoice_size_ELT AS \n",
    "            SELECT \n",
    "                C.CustomerId,\n",
    "                C.FirstName,\n",
    "                C.LastName,\n",
    "                COUNT(I.InvoiceId) AS loyalty_score,\n",
    "                AVG(IL.total_spend) AS avg_invoice_size,\n",
    "                CURRENT_TIMESTAMP AS created_at,\n",
    "                CURRENT_TIMESTAMP AS updated_at,\n",
    "                'process:SL' AS updated_by\n",
    "            FROM \n",
    "                Customers C\n",
    "            LEFT JOIN Invoices I ON C.CustomerId = I.CustomerId\n",
    "            LEFT JOIN (\n",
    "                SELECT InvoiceId, SUM(UnitPrice * Quantity) AS total_spend\n",
    "                FROM Invoices_Line\n",
    "                GROUP BY InvoiceId\n",
    "            ) IL ON I.InvoiceId = IL.InvoiceId\n",
    "            GROUP BY \n",
    "                C.CustomerId, C.FirstName, C.LastName;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the transformation query\n",
    "        conn.execute(transform_query)\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        # Close the SQLite connection and stop Spark session\n",
    "        conn.close()  # Close the SQLite connection\n",
    "        \n",
    "load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba8d49ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Updated: 2024-09-14 21:58:31\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def incremental_load():\n",
    "    conn = sqlite3.connect('../../../Customers_ELT.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # EXTRACT (Loading CSVs from local storage)\n",
    "        customers = pd.read_csv(\"../../../Customer.csv\")\n",
    "        invoices = pd.read_csv(\"../../../Invoice.csv\")\n",
    "        invoice_lines = pd.read_csv(\"../../../InvoiceLine.csv\")\n",
    "\n",
    "        # Check if the 'customer_loyalty' table exists\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT name FROM sqlite_master WHERE type='table' AND name='customer_loyalty_and_invoice_size_ELT';\n",
    "        \"\"\")\n",
    "        table_exists = cursor.fetchone()\n",
    "\n",
    "        # If the table exists, get the latest processed updated_at from the customer_loyalty table\n",
    "        if table_exists:\n",
    "            latest_updated_at_query = \"SELECT MAX(updated_at) FROM customer_loyalty_and_invoice_size_ELT\"\n",
    "            cursor.execute(latest_updated_at_query)\n",
    "            last_updated = cursor.fetchone()[0]\n",
    "\n",
    "        if not table_exists or last_updated is None:\n",
    "            last_updated = '1900-01-01 00:00:00'  # Default to a very old timestamp\n",
    "            \n",
    "        # Convert last_updated to a datetime object\n",
    "        last_updated = pd.to_datetime(last_updated)\n",
    "        print(f\"Last Updated: {last_updated}\")\n",
    "\n",
    "        # Convert 'UpdatedAt' columns in CSVs to datetime, assuming format is DD/MM/YYYY\n",
    "        customers['UpdatedAt'] = pd.to_datetime(customers['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "        invoices['UpdatedAt'] = pd.to_datetime(invoices['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "        invoice_lines['UpdatedAt'] = pd.to_datetime(invoice_lines['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "\n",
    "        # Filter rows that have been created or updated after the last load\n",
    "        customers_filtered = customers[customers['UpdatedAt'] > last_updated]\n",
    "        invoices_filtered = invoices[invoices['UpdatedAt'] > last_updated]\n",
    "        invoice_lines_filtered = invoice_lines[invoice_lines['UpdatedAt'] > last_updated]\n",
    "\n",
    "        # Load filtered data into temporary tables\n",
    "        customers_filtered.to_sql('Customers_temp', conn, if_exists='replace', index=False)\n",
    "        invoices_filtered.to_sql('Invoices_temp', conn, if_exists='replace', index=False)\n",
    "        invoice_lines_filtered.to_sql('Invoices_Line_temp', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # Save historical data for customers to be updated (loyalty_score, avg_invoice_size, created_at)\n",
    "        conn.execute(\"\"\"DROP TABLE IF EXISTS customers_old_data_temp\"\"\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE customers_old_data_temp AS\n",
    "            SELECT CustomerId, loyalty_score, avg_invoice_size, created_at\n",
    "            FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Remove the existing rows from the target table for customers being updated\n",
    "        conn.execute(\"\"\"\n",
    "            DELETE FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # TRANSFORM (Perform transformations and combine with old data)\n",
    "        transform_query = \"\"\"\n",
    "            INSERT INTO customer_loyalty_and_invoice_size_ELT \n",
    "            (CustomerId, FirstName, LastName, loyalty_score, avg_invoice_size, created_at, updated_at, updated_by)\n",
    "            SELECT \n",
    "                C.CustomerId,\n",
    "                C.FirstName,\n",
    "                C.LastName,\n",
    "                COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId) AS loyalty_score,  -- Combine old and new loyalty score\n",
    "                (\n",
    "                    (COALESCE(O.loyalty_score, 0) * COALESCE(O.avg_invoice_size, 0)) + SUM(IL.total_spend)\n",
    "                ) / NULLIF(COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId), 0) AS avg_invoice_size,  -- Combine old and new avg invoice size\n",
    "                COALESCE(O.created_at, CURRENT_TIMESTAMP) AS created_at,  -- Retain old created_at or set to current\n",
    "                CURRENT_TIMESTAMP AS updated_at,\n",
    "                'process:SL' AS updated_by\n",
    "            FROM \n",
    "                Customers_temp C\n",
    "            LEFT JOIN Invoices_temp I ON C.CustomerId = I.CustomerId\n",
    "            LEFT JOIN (\n",
    "                SELECT InvoiceId, SUM(UnitPrice * Quantity) AS total_spend\n",
    "                FROM Invoices_Line_temp\n",
    "                GROUP BY InvoiceId\n",
    "            ) IL ON I.InvoiceId = IL.InvoiceId\n",
    "            LEFT JOIN customers_old_data_temp O ON C.CustomerId = O.CustomerId\n",
    "            GROUP BY \n",
    "                C.CustomerId, C.FirstName, C.LastName;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the transformation query\n",
    "        conn.execute(transform_query)\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        # Clean up temporary tables\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Customers_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_Line_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS customers_old_data_temp\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Close the SQLite connection\n",
    "        conn.close()\n",
    "incremental_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8fcc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#efrat's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e101d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Updated: 2024-09-14 21:58:31\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def load():\n",
    "    conn = sqlite3.connect('../../../Customers_ELT.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # EXTRACT (Loading CSVs from local storage)\n",
    "        customers = pd.read_csv(\"../../../Customer.csv\")\n",
    "        invoices = pd.read_csv(\"../../../Invoice.csv\")\n",
    "        invoice_lines = pd.read_csv(\"../../../InvoiceLine.csv\")\n",
    "\n",
    "        # Check if the 'customer_loyalty' table exists\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT name FROM sqlite_master WHERE type='table' AND name='customer_loyalty_and_invoice_size_ELT';\n",
    "        \"\"\")\n",
    "        table_exists = cursor.fetchone()\n",
    "\n",
    "        # If the table exists, get the latest processed updated_at from the customer_loyalty table\n",
    "        if table_exists:\n",
    "            latest_updated_at_query = \"SELECT MAX(updated_at) FROM customer_loyalty_and_invoice_size_ELT\"\n",
    "            cursor.execute(latest_updated_at_query)\n",
    "            last_updated = cursor.fetchone()[0]\n",
    "        else:\n",
    "            last_updated = None\n",
    "\n",
    "        if not last_updated:\n",
    "            last_updated = '1900-01-01 00:00:00'  # Default to a very old timestamp\n",
    "\n",
    "        # Convert last_updated to a datetime object\n",
    "        last_updated = pd.to_datetime(last_updated)\n",
    "        print(f\"Last Updated: {last_updated}\")\n",
    "\n",
    "        # Convert 'UpdatedAt' columns in CSVs to datetime, assuming format is DD/MM/YYYY\n",
    "        customers['UpdatedAt'] = pd.to_datetime(customers['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "        invoices['UpdatedAt'] = pd.to_datetime(invoices['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "        invoice_lines['UpdatedAt'] = pd.to_datetime(invoice_lines['UpdatedAt'], dayfirst=True, errors='coerce')\n",
    "\n",
    "        # Filter rows that have been created or updated after the last load\n",
    "        customers_filtered = customers[customers['UpdatedAt'] > last_updated]\n",
    "        invoices_filtered = invoices[invoices['UpdatedAt'] > last_updated]\n",
    "        invoice_lines_filtered = invoice_lines[invoice_lines['UpdatedAt'] > last_updated]\n",
    "\n",
    "        # Load filtered data into temporary tables\n",
    "        customers_filtered.to_sql('Customers_temp', conn, if_exists='replace', index=False)\n",
    "        invoices_filtered.to_sql('Invoices_temp', conn, if_exists='replace', index=False)\n",
    "        invoice_lines_filtered.to_sql('Invoices_Line_temp', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # Save historical data for customers to be updated (loyalty_score, avg_invoice_size, created_at)\n",
    "        conn.execute(\"\"\"DROP TABLE IF EXISTS customers_old_data_temp\"\"\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE customers_old_data_temp AS\n",
    "            SELECT CustomerId, loyalty_score, avg_invoice_size, created_at\n",
    "            FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Remove the existing rows from the target table for customers being updated\n",
    "        conn.execute(\"\"\"\n",
    "            DELETE FROM customer_loyalty_and_invoice_size_ELT\n",
    "            WHERE CustomerId IN (SELECT CustomerId FROM Customers_temp)\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # TRANSFORM (Insert or update existing records with new data)\n",
    "        transform_query = \"\"\"\n",
    "            INSERT INTO customer_loyalty_and_invoice_size_ELT \n",
    "            (CustomerId, FirstName, LastName, loyalty_score, avg_invoice_size, created_at, updated_at, updated_by)\n",
    "            SELECT \n",
    "                C.CustomerId,\n",
    "                C.FirstName,\n",
    "                C.LastName,\n",
    "                COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId) AS loyalty_score,  -- Combine old and new loyalty score\n",
    "                (\n",
    "                    (COALESCE(O.loyalty_score, 0) * COALESCE(O.avg_invoice_size, 0)) + SUM(IL.total_spend)\n",
    "                ) / NULLIF(COALESCE(O.loyalty_score, 0) + COUNT(I.InvoiceId), 0) AS avg_invoice_size,  -- Combine old and new avg invoice size\n",
    "                COALESCE(O.created_at, CURRENT_TIMESTAMP) AS created_at,  -- Retain old created_at or set to current\n",
    "                CURRENT_TIMESTAMP AS updated_at,\n",
    "                'process:SL' AS updated_by\n",
    "            FROM \n",
    "                Customers_temp C\n",
    "            LEFT JOIN Invoices_temp I ON C.CustomerId = I.CustomerId\n",
    "            LEFT JOIN (\n",
    "                SELECT InvoiceId, SUM(UnitPrice * Quantity) AS total_spend\n",
    "                FROM Invoices_Line_temp\n",
    "                GROUP BY InvoiceId\n",
    "            ) IL ON I.InvoiceId = IL.InvoiceId\n",
    "            LEFT JOIN customers_old_data_temp O ON C.CustomerId = O.CustomerId\n",
    "            GROUP BY \n",
    "                C.CustomerId, C.FirstName, C.LastName;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the transformation query\n",
    "        conn.execute(transform_query)\n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        # Clean up temporary tables\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Customers_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS Invoices_Line_temp\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS customers_old_data_temp\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Close the SQLite connection\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d72ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
